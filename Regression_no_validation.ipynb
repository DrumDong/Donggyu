{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ehdrb\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ehdrb\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ehdrb\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ehdrb\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ehdrb\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ehdrb\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1750.0341 - mean_absolute_error: 37.9258\n",
      "Epoch 2/100\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1673.6318 - mean_absolute_error: 36.9317\n",
      "Epoch 3/100\n",
      "700/700 [==============================] - 0s 48us/step - loss: 1606.2386 - mean_absolute_error: 36.0203\n",
      "Epoch 4/100\n",
      "700/700 [==============================] - 0s 54us/step - loss: 1550.0178 - mean_absolute_error: 35.2383\n",
      "Epoch 5/100\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1501.1257 - mean_absolute_error: 34.5425\n",
      "Epoch 6/100\n",
      "700/700 [==============================] - 0s 50us/step - loss: 1456.4813 - mean_absolute_error: 33.8969\n",
      "Epoch 7/100\n",
      "700/700 [==============================] - 0s 51us/step - loss: 1417.0199 - mean_absolute_error: 33.3086\n",
      "Epoch 8/100\n",
      "700/700 [==============================] - 0s 53us/step - loss: 1382.1527 - mean_absolute_error: 32.7884\n",
      "Epoch 9/100\n",
      "700/700 [==============================] - 0s 51us/step - loss: 1351.7378 - mean_absolute_error: 32.3154\n",
      "Epoch 10/100\n",
      "700/700 [==============================] - 0s 41us/step - loss: 1324.1028 - mean_absolute_error: 31.8894\n",
      "Epoch 11/100\n",
      "700/700 [==============================] - 0s 47us/step - loss: 1298.4767 - mean_absolute_error: 31.4885\n",
      "Epoch 12/100\n",
      "700/700 [==============================] - 0s 43us/step - loss: 1274.7798 - mean_absolute_error: 31.1098\n",
      "Epoch 13/100\n",
      "700/700 [==============================] - 0s 53us/step - loss: 1252.0662 - mean_absolute_error: 30.7496\n",
      "Epoch 14/100\n",
      "700/700 [==============================] - 0s 47us/step - loss: 1231.4160 - mean_absolute_error: 30.4102\n",
      "Epoch 15/100\n",
      "700/700 [==============================] - 0s 43us/step - loss: 1212.1734 - mean_absolute_error: 30.0984\n",
      "Epoch 16/100\n",
      "700/700 [==============================] - 0s 39us/step - loss: 1194.6417 - mean_absolute_error: 29.8148\n",
      "Epoch 17/100\n",
      "700/700 [==============================] - 0s 31us/step - loss: 1178.8693 - mean_absolute_error: 29.5590\n",
      "Epoch 18/100\n",
      "700/700 [==============================] - 0s 41us/step - loss: 1164.5052 - mean_absolute_error: 29.3244\n",
      "Epoch 19/100\n",
      "700/700 [==============================] - 0s 48us/step - loss: 1151.1762 - mean_absolute_error: 29.1093\n",
      "Epoch 20/100\n",
      "700/700 [==============================] - 0s 40us/step - loss: 1138.7852 - mean_absolute_error: 28.9073\n",
      "Epoch 21/100\n",
      "700/700 [==============================] - 0s 47us/step - loss: 1127.4339 - mean_absolute_error: 28.7159\n",
      "Epoch 22/100\n",
      "700/700 [==============================] - 0s 31us/step - loss: 1116.1559 - mean_absolute_error: 28.5307\n",
      "Epoch 23/100\n",
      "700/700 [==============================] - 0s 37us/step - loss: 1105.4913 - mean_absolute_error: 28.3559\n",
      "Epoch 24/100\n",
      "700/700 [==============================] - 0s 38us/step - loss: 1095.2249 - mean_absolute_error: 28.1834\n",
      "Epoch 25/100\n",
      "700/700 [==============================] - 0s 37us/step - loss: 1085.3429 - mean_absolute_error: 28.0163\n",
      "Epoch 26/100\n",
      "700/700 [==============================] - 0s 36us/step - loss: 1075.3947 - mean_absolute_error: 27.8537\n",
      "Epoch 27/100\n",
      "700/700 [==============================] - 0s 36us/step - loss: 1066.0467 - mean_absolute_error: 27.6946\n",
      "Epoch 28/100\n",
      "700/700 [==============================] - 0s 37us/step - loss: 1056.7003 - mean_absolute_error: 27.5396\n",
      "Epoch 29/100\n",
      "700/700 [==============================] - 0s 46us/step - loss: 1047.6581 - mean_absolute_error: 27.3884\n",
      "Epoch 30/100\n",
      "700/700 [==============================] - 0s 44us/step - loss: 1038.7273 - mean_absolute_error: 27.2368\n",
      "Epoch 31/100\n",
      "700/700 [==============================] - 0s 54us/step - loss: 1029.8811 - mean_absolute_error: 27.0896\n",
      "Epoch 32/100\n",
      "700/700 [==============================] - 0s 40us/step - loss: 1021.2720 - mean_absolute_error: 26.9468\n",
      "Epoch 33/100\n",
      "700/700 [==============================] - 0s 38us/step - loss: 1012.8898 - mean_absolute_error: 26.8030\n",
      "Epoch 34/100\n",
      "700/700 [==============================] - 0s 46us/step - loss: 1004.5434 - mean_absolute_error: 26.6615\n",
      "Epoch 35/100\n",
      "700/700 [==============================] - 0s 41us/step - loss: 996.3919 - mean_absolute_error: 26.5232\n",
      "Epoch 36/100\n",
      "700/700 [==============================] - 0s 46us/step - loss: 988.3304 - mean_absolute_error: 26.3856\n",
      "Epoch 37/100\n",
      "700/700 [==============================] - 0s 67us/step - loss: 980.3118 - mean_absolute_error: 26.2492\n",
      "Epoch 38/100\n",
      "700/700 [==============================] - 0s 51us/step - loss: 972.4987 - mean_absolute_error: 26.1156\n",
      "Epoch 39/100\n",
      "700/700 [==============================] - 0s 60us/step - loss: 964.6204 - mean_absolute_error: 25.9829\n",
      "Epoch 40/100\n",
      "700/700 [==============================] - 0s 68us/step - loss: 957.0524 - mean_absolute_error: 25.8531\n",
      "Epoch 41/100\n",
      "700/700 [==============================] - 0s 56us/step - loss: 949.4967 - mean_absolute_error: 25.7238\n",
      "Epoch 42/100\n",
      "700/700 [==============================] - 0s 47us/step - loss: 942.0339 - mean_absolute_error: 25.5954\n",
      "Epoch 43/100\n",
      "700/700 [==============================] - 0s 50us/step - loss: 934.6240 - mean_absolute_error: 25.4694\n",
      "Epoch 44/100\n",
      "700/700 [==============================] - ETA: 0s - loss: 876.5413 - mean_absolute_error: 24.28 - 0s 38us/step - loss: 927.4019 - mean_absolute_error: 25.3446\n",
      "Epoch 45/100\n",
      "700/700 [==============================] - 0s 51us/step - loss: 920.1554 - mean_absolute_error: 25.2219\n",
      "Epoch 46/100\n",
      "700/700 [==============================] - 0s 43us/step - loss: 912.9740 - mean_absolute_error: 25.0989\n",
      "Epoch 47/100\n",
      "700/700 [==============================] - 0s 38us/step - loss: 905.9958 - mean_absolute_error: 24.9787\n",
      "Epoch 48/100\n",
      "700/700 [==============================] - 0s 39us/step - loss: 899.0183 - mean_absolute_error: 24.8601\n",
      "Epoch 49/100\n",
      "700/700 [==============================] - 0s 27us/step - loss: 892.1653 - mean_absolute_error: 24.7434\n",
      "Epoch 50/100\n",
      "700/700 [==============================] - 0s 27us/step - loss: 885.3538 - mean_absolute_error: 24.6245\n",
      "Epoch 51/100\n",
      "700/700 [==============================] - 0s 44us/step - loss: 878.6157 - mean_absolute_error: 24.5117\n",
      "Epoch 52/100\n",
      "700/700 [==============================] - 0s 23us/step - loss: 871.9272 - mean_absolute_error: 24.3981\n",
      "Epoch 53/100\n",
      "700/700 [==============================] - 0s 38us/step - loss: 865.3546 - mean_absolute_error: 24.2838\n",
      "Epoch 54/100\n",
      "700/700 [==============================] - 0s 65us/step - loss: 858.8305 - mean_absolute_error: 24.1719\n",
      "Epoch 55/100\n",
      "700/700 [==============================] - 0s 117us/step - loss: 852.3858 - mean_absolute_error: 24.0614\n",
      "Epoch 56/100\n",
      "700/700 [==============================] - 0s 115us/step - loss: 845.9921 - mean_absolute_error: 23.9494\n",
      "Epoch 57/100\n",
      "700/700 [==============================] - 0s 67us/step - loss: 839.6525 - mean_absolute_error: 23.8407\n",
      "Epoch 58/100\n",
      "700/700 [==============================] - 0s 37us/step - loss: 833.4411 - mean_absolute_error: 23.7333\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 34us/step - loss: 827.2618 - mean_absolute_error: 23.6257\n",
      "Epoch 60/100\n",
      "700/700 [==============================] - 0s 56us/step - loss: 821.0734 - mean_absolute_error: 23.5182\n",
      "Epoch 61/100\n",
      "700/700 [==============================] - 0s 36us/step - loss: 814.9921 - mean_absolute_error: 23.4159\n",
      "Epoch 62/100\n",
      "700/700 [==============================] - 0s 53us/step - loss: 809.1090 - mean_absolute_error: 23.3116\n",
      "Epoch 63/100\n",
      "700/700 [==============================] - 0s 67us/step - loss: 803.1436 - mean_absolute_error: 23.2083\n",
      "Epoch 64/100\n",
      "700/700 [==============================] - 0s 120us/step - loss: 797.1962 - mean_absolute_error: 23.1057\n",
      "Epoch 65/100\n",
      "700/700 [==============================] - 0s 266us/step - loss: 791.4093 - mean_absolute_error: 23.0076\n",
      "Epoch 66/100\n",
      "700/700 [==============================] - 0s 158us/step - loss: 785.6237 - mean_absolute_error: 22.9075\n",
      "Epoch 67/100\n",
      "700/700 [==============================] - 0s 31us/step - loss: 779.9058 - mean_absolute_error: 22.8115\n",
      "Epoch 68/100\n",
      "700/700 [==============================] - 0s 48us/step - loss: 774.3191 - mean_absolute_error: 22.7133\n",
      "Epoch 69/100\n",
      "700/700 [==============================] - 0s 57us/step - loss: 768.8188 - mean_absolute_error: 22.6165\n",
      "Epoch 70/100\n",
      "700/700 [==============================] - 0s 59us/step - loss: 763.1434 - mean_absolute_error: 22.5193\n",
      "Epoch 71/100\n",
      "700/700 [==============================] - 0s 61us/step - loss: 757.6308 - mean_absolute_error: 22.4253\n",
      "Epoch 72/100\n",
      "700/700 [==============================] - 0s 48us/step - loss: 752.2999 - mean_absolute_error: 22.3309\n",
      "Epoch 73/100\n",
      "700/700 [==============================] - 0s 38us/step - loss: 746.8919 - mean_absolute_error: 22.2342\n",
      "Epoch 74/100\n",
      "700/700 [==============================] - 0s 48us/step - loss: 741.5933 - mean_absolute_error: 22.1396\n",
      "Epoch 75/100\n",
      "700/700 [==============================] - 0s 43us/step - loss: 736.2851 - mean_absolute_error: 22.0464\n",
      "Epoch 76/100\n",
      "700/700 [==============================] - 0s 42us/step - loss: 731.1333 - mean_absolute_error: 21.9550\n",
      "Epoch 77/100\n",
      "700/700 [==============================] - 0s 37us/step - loss: 725.9407 - mean_absolute_error: 21.8622\n",
      "Epoch 78/100\n",
      "700/700 [==============================] - 0s 41us/step - loss: 720.9487 - mean_absolute_error: 21.7711\n",
      "Epoch 79/100\n",
      "700/700 [==============================] - 0s 49us/step - loss: 715.7667 - mean_absolute_error: 21.6801\n",
      "Epoch 80/100\n",
      "700/700 [==============================] - 0s 51us/step - loss: 710.7360 - mean_absolute_error: 21.5926\n",
      "Epoch 81/100\n",
      "700/700 [==============================] - 0s 46us/step - loss: 705.7972 - mean_absolute_error: 21.5043\n",
      "Epoch 82/100\n",
      "700/700 [==============================] - 0s 41us/step - loss: 700.8614 - mean_absolute_error: 21.4180\n",
      "Epoch 83/100\n",
      "700/700 [==============================] - 0s 64us/step - loss: 696.1088 - mean_absolute_error: 21.3332\n",
      "Epoch 84/100\n",
      "700/700 [==============================] - 0s 58us/step - loss: 691.3511 - mean_absolute_error: 21.2483\n",
      "Epoch 85/100\n",
      "700/700 [==============================] - 0s 48us/step - loss: 686.4730 - mean_absolute_error: 21.1622\n",
      "Epoch 86/100\n",
      "700/700 [==============================] - 0s 58us/step - loss: 681.7301 - mean_absolute_error: 21.0777\n",
      "Epoch 87/100\n",
      "700/700 [==============================] - 0s 40us/step - loss: 677.0732 - mean_absolute_error: 20.9966\n",
      "Epoch 88/100\n",
      "700/700 [==============================] - 0s 48us/step - loss: 672.5456 - mean_absolute_error: 20.9130\n",
      "Epoch 89/100\n",
      "700/700 [==============================] - 0s 54us/step - loss: 667.9323 - mean_absolute_error: 20.8291\n",
      "Epoch 90/100\n",
      "700/700 [==============================] - 0s 61us/step - loss: 663.4220 - mean_absolute_error: 20.7478\n",
      "Epoch 91/100\n",
      "700/700 [==============================] - 0s 51us/step - loss: 658.8843 - mean_absolute_error: 20.6650\n",
      "Epoch 92/100\n",
      "700/700 [==============================] - 0s 73us/step - loss: 654.5657 - mean_absolute_error: 20.5858\n",
      "Epoch 93/100\n",
      "700/700 [==============================] - 0s 58us/step - loss: 650.1038 - mean_absolute_error: 20.5041\n",
      "Epoch 94/100\n",
      "700/700 [==============================] - 0s 63us/step - loss: 645.7642 - mean_absolute_error: 20.4240\n",
      "Epoch 95/100\n",
      "700/700 [==============================] - 0s 58us/step - loss: 641.4323 - mean_absolute_error: 20.3441\n",
      "Epoch 96/100\n",
      "700/700 [==============================] - 0s 58us/step - loss: 637.1794 - mean_absolute_error: 20.2660\n",
      "Epoch 97/100\n",
      "700/700 [==============================] - 0s 44us/step - loss: 633.0381 - mean_absolute_error: 20.1895\n",
      "Epoch 98/100\n",
      "700/700 [==============================] - 0s 48us/step - loss: 628.7788 - mean_absolute_error: 20.1098\n",
      "Epoch 99/100\n",
      "700/700 [==============================] - 0s 48us/step - loss: 624.7468 - mean_absolute_error: 20.0355\n",
      "Epoch 100/100\n",
      "700/700 [==============================] - 0s 63us/step - loss: 620.5542 - mean_absolute_error: 19.9571\n",
      "330/330 [==============================] - 0s 529us/step\n",
      "mean_absolute_error: 14.68\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#0.사용할 패키지 불러오기\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#랜덤시드 고정시키기\n",
    "np.random.seed(5)\n",
    "\n",
    "#1.데이터 준비하기\n",
    "dataset = pd.read_csv('concrete.csv')\n",
    "dataset = dataset.values\n",
    "\n",
    "#2.데이터셋 생성하기\n",
    "y = dataset[:,8]\n",
    "x = dataset[:,:8]\n",
    "\n",
    "x_train = x[0:700,]\n",
    "y_train = y[0:700,]\n",
    "x_test = x[700:,]\n",
    "y_test = y[700:,]\n",
    "\n",
    "#3.모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=8, activation='tanh'))\n",
    "model.add(Dense(20, activation='tanh'))\n",
    "model.add(Dense(20, activation='tanh'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "#4.모델 학습과정 설정하기\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "\n",
    "#5.모델 학습시키기\n",
    "hist = model.fit(x_train, y_train, epochs=100, batch_size = 100)\n",
    "\n",
    "#6.모델 평가하기\n",
    "scores = model.evaluate(x_test, y_test)\n",
    "print(\"%s: %.2f\" %(model.metrics_names[1], scores[1]))\n",
    "\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "loss_ax.plot(hist.history['loss'],'y', label='train loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# 7. 예측하기\n",
    "y_predict = model.predict(x_test)\n",
    "\n",
    "df = pd.DataFrame(y_predict)\n",
    "df.insert(1,'y_test',y_test)\n",
    "df.to_csv(\"predict_regression.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
