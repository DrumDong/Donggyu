{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab 10:NN,Relu,Xavier,Dropout, and Adam.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DrumDong/Donggyu/blob/master/%EB%AA%A8%EB%91%90%EB%A5%BC%20%EC%9C%84%ED%95%9C%20%EB%94%A5%EB%9F%AC%EB%8B%9D/lab_10_NN%2CRelu%2CXavier%2CDropout%2C_and_Adam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA1zKyXWFFaR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ea44ad62-6bc7-4327-92ce-f735d537315a"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "tf.__version__"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.15.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iC797aixHD5m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhjOxUzkMh9x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.set_random_seed(777)  # reproducibility"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qkpVjNaMizh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "96c27ce8-4e8a-4ae3-b100-d23f5d5485ed"
      },
      "source": [
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDiOGxxRCsk6",
        "colab_type": "text"
      },
      "source": [
        "# Softmax classifier for MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDvrGpJRDyzn",
        "colab_type": "text"
      },
      "source": [
        "## input place holder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yamgms5CDLKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = tf.placeholder(tf.float32,[None,784])\n",
        "Y = tf.placeholder(tf.float32,[None,10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coJC93ErD1bi",
        "colab_type": "text"
      },
      "source": [
        "## weight & bias for nn layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fr7AjKHZD5V6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W = tf.Variable(tf.random_normal([784,10]))\n",
        "b = tf.Variable(tf.random_normal([10]))\n",
        "\n",
        "hypothesis = tf.matmul(X, W) + b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0Qd-TvrE1Um",
        "colab_type": "text"
      },
      "source": [
        "## define cost/loss & optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-AjkF6jE6Eu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cost = tf.reduce_mean(\n",
        "    tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis,labels=Y))\n",
        "train = tf.train.AdamOptimizer(learning_rate=0.1).minimize(cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEHUqumlLCgY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test model\n",
        "correct_prediction = tf.equal(tf.argmax(hypothesis, axis=1), tf.argmax(Y, axis=1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0QLZbbrFgYN",
        "colab_type": "text"
      },
      "source": [
        "## initialize & train my model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "watlEhoyNmfe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# parameters\n",
        "learning_rate = 0.001\n",
        "batch_size = 100\n",
        "num_epochs = 15\n",
        "num_iterations = int(mnist.train.num_examples / batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82camMNVFnSC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "66755732-d990-4b29-9a94-c84d2c2aeaa1"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    # initialize\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        avg_cost = 0\n",
        "\n",
        "        for iteration in range(num_iterations):\n",
        "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "            _, cost_val = sess.run([train, cost], feed_dict={X: batch_xs, Y: batch_ys})\n",
        "            avg_cost += cost_val / num_iterations\n",
        "\n",
        "        print(f\"Epoch: {(epoch + 1):04d}, Cost: {avg_cost:.9f}\")\n",
        "\n",
        "    print(\"Learning Finished!\")\n",
        "\n",
        "    # Test model and check accuracy\n",
        "    print(\n",
        "        \"Accuracy:\",\n",
        "        sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels}),\n",
        "    )\n",
        "\n",
        "    # Get one and predict\n",
        "    r = random.randint(0, mnist.test.num_examples - 1)\n",
        "\n",
        "    print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r : r + 1], axis=1)))\n",
        "    print(\n",
        "        \"Prediction: \",\n",
        "        sess.run(\n",
        "            tf.argmax(hypothesis, axis=1), feed_dict={X: mnist.test.images[r : r + 1]}\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    plt.imshow(\n",
        "        mnist.test.images[r : r + 1].reshape(28, 28),\n",
        "        cmap=\"Greys\",\n",
        "        interpolation=\"nearest\",\n",
        "    )\n",
        "    plt.show()"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0001, Cost: 1.098952134\n",
            "Epoch: 0002, Cost: 0.964111220\n",
            "Epoch: 0003, Cost: 1.008151440\n",
            "Epoch: 0004, Cost: 0.998561974\n",
            "Epoch: 0005, Cost: 1.052424902\n",
            "Epoch: 0006, Cost: 1.032911811\n",
            "Epoch: 0007, Cost: 1.008525430\n",
            "Epoch: 0008, Cost: 1.072904515\n",
            "Epoch: 0009, Cost: 1.020719459\n",
            "Epoch: 0010, Cost: 1.035737923\n",
            "Epoch: 0011, Cost: 1.058077699\n",
            "Epoch: 0012, Cost: 1.025192826\n",
            "Epoch: 0013, Cost: 1.005007957\n",
            "Epoch: 0014, Cost: 1.002504927\n",
            "Epoch: 0015, Cost: 1.069474817\n",
            "Learning Finished!\n",
            "Accuracy: 0.9029\n",
            "Label:  [1]\n",
            "Prediction:  [1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAM0klEQVR4nO3db6hc9Z3H8c9n3caILRg3lxBs8HaL\nDwzKpmWICxH/lQSTJ7EQpQFLVsT0gWIrATd0hSr6IMjasoElkpqQ69K1VtpgHoTdxljQPglOQtSo\nuGZDQhNiMlE0iT7Iar774B7Lrblz5jrnzJxpvu8XDHPmfOec82XIJ2fm/GbuzxEhABe/v2m6AQDD\nQdiBJAg7kARhB5Ig7EASfzvMg82dOzfGx8eHeUgglcOHD+vUqVOerlYp7LZvl/Rvki6R9ExEbCh7\n/vj4uNrtdpVDAijRarW61vp+G2/7Ekn/Lmm5pIWSVtte2O/+AAxWlc/siyUdjIhDEXFO0q8lrayn\nLQB1qxL2qyT9acrjo8W6v2B7re227Xan06lwOABVDPxqfERsjohWRLTGxsYGfTgAXVQJ+zFJC6Y8\n/maxDsAIqhL21yRdY/tbtmdJ+oGkHfW0BaBufQ+9RcRnth+Q9N+aHHrbGhFv1dYZgFpVGmePiJ2S\ndtbUC4AB4uuyQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiB\nJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiQx1CmbgTqdPn26tH7TTTd1rS1ZsqR02/Xr15fWFyxY\nUFofRZzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtkxsnqNoz/zzDOl9Xfffbdr7cCBA6XbLlu2\nrLT+1zjOXinstg9LOiPpc0mfRUSrjqYA1K+OM/utEXGqhv0AGCA+swNJVA17SPq97b221073BNtr\nbbdttzudTsXDAehX1bDfGBHflbRc0v22L/jlQURsjohWRLTGxsYqHg5AvyqFPSKOFfcnJW2XtLiO\npgDUr++w277c9je+WJa0TFL5eAaAxlS5Gj9P0nbbX+znPyPiv2rpCil8/PHHpfUtW7aU1h9++OG+\nj3333XeX1pcvX973vkdV32GPiEOS/qHGXgAMEENvQBKEHUiCsANJEHYgCcIOJMFPXNGYF154obRe\nZWhNkq699tqutaeffrp021mzZlU69ijizA4kQdiBJAg7kARhB5Ig7EAShB1IgrADSTDOjoE6e/Zs\n19qTTz450GM//vjjXWuzZ88e6LFHEWd2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCcXZU8sknn5TW\nn3322a61Q4cOlW57xRVXlNbvvPPO0nqvaZez4cwOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kwzo5K\ndu3aVVp/8MEH+9730qVLS+ubNm3qe98Z9Tyz295q+6TtA1PWXWl7l+33ivs5g20TQFUzeRu/TdLt\nX1q3XtLuiLhG0u7iMYAR1jPsEfGKpA+/tHqlpIlieULSHTX3BaBm/V6gmxcRx4vl9yXN6/ZE22tt\nt223O51On4cDUFXlq/EREZKipL45IloR0RobG6t6OAB96jfsJ2zPl6Ti/mR9LQEYhH7DvkPSmmJ5\njaQX62kHwKD0HGe3/ZykWyTNtX1U0s8kbZD0G9v3Sjoi6a5BNonmnDlzprQ+MTFRWsfo6Bn2iFjd\npfS9mnsBMEB8XRZIgrADSRB2IAnCDiRB2IEk+Ilrcnv37i2tL168uLRuu+9jb9y4sbR+ww039L1v\nXIgzO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kwTh7cq+++upA93/zzTd3rd1zzz2l21522WV1t5Ma\nZ3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJx9ovcvn37Suvr1q0rrZ8/f760ftttt5XWd+7c2bV2\n6aWXlm6LenFmB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkGGe/COzZs6dr7dZbby3dttfffa8yji4x\nlj5Kep7ZbW+1fdL2gSnrHrV9zPb+4rZisG0CqGomb+O3Sbp9mvW/iIhFxa38v3cAjesZ9oh4RdKH\nQ+gFwABVuUD3gO03irf5c7o9yfZa223b7U6nU+FwAKroN+ybJH1b0iJJxyU91e2JEbE5IloR0Rob\nG+vzcACq6ivsEXEiIj6PiPOSfimpfKpPAI3rK+y25095+H1JB7o9F8Bo6DnObvs5SbdImmv7qKSf\nSbrF9iJJIemwpB8NsMf0Pvjgg9L60qVLu9bOnTtX6diMo188eoY9IlZPs3rLAHoBMEB8XRZIgrAD\nSRB2IAnCDiRB2IEk+InrX4GDBw+W1j/99NOBHZuhtYsHZ3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQd\nSIJx9iE4cuRIaf2+++4rrb/++uul9dmzZ3etrVq1qnTbxx57rLSOiwdndiAJwg4kQdiBJAg7kARh\nB5Ig7EAShB1IgnH2IXjqqa4T5kiSXn755Ur7v/rqq7vWtm3bVmnfuHhwZgeSIOxAEoQdSIKwA0kQ\ndiAJwg4kQdiBJBhnr8G+fftK688//3yl/Y+Pj5fWH3nkkUr7Rw49z+y2F9j+g+23bb9l+8fF+itt\n77L9XnE/Z/DtAujXTN7GfyZpXUQslPSPku63vVDSekm7I+IaSbuLxwBGVM+wR8TxiNhXLJ+R9I6k\nqyStlDRRPG1C0h2DahJAdV/pAp3tcUnfkbRH0ryIOF6U3pc0r8s2a223bbc7nU6FVgFUMeOw2/66\npN9K+klEnJ5ai4iQFNNtFxGbI6IVEa2xsbFKzQLo34zCbvtrmgz6ryLid8XqE7bnF/X5kk4OpkUA\ndeg59GbbkrZIeicifj6ltEPSGkkbivsXB9LhkJw7d660vmHDhq61jRs3lm770UcfldZ7TYu8ffv2\n0vr1119fWgekmY2zL5H0Q0lv2t5frPupJkP+G9v3Sjoi6a7BtAigDj3DHhF/lOQu5e/V2w6AQeHr\nskAShB1IgrADSRB2IAnCDiTBT1wLL730Umn9iSee6Fo7f/586bYLFy4srW/atKm0zjg66sCZHUiC\nsANJEHYgCcIOJEHYgSQIO5AEYQeSYJy9sGLFitL6Qw891LXWa0rmVatWldavu+660jpQB87sQBKE\nHUiCsANJEHYgCcIOJEHYgSQIO5CEJydzGY5WqxXtdntoxwOyabVaarfb0/41aM7sQBKEHUiCsANJ\nEHYgCcIOJEHYgSQIO5BEz7DbXmD7D7bftv2W7R8X6x+1fcz2/uJW/oNwAI2ayR+v+EzSuojYZ/sb\nkvba3lXUfhER/zq49gDUZSbzsx+XdLxYPmP7HUlXDboxAPX6Sp/ZbY9L+o6kPcWqB2y/YXur7Tld\ntllru2273el0KjULoH8zDrvtr0v6raSfRMRpSZskfVvSIk2e+af9Q2wRsTkiWhHRGhsbq6FlAP2Y\nUdhtf02TQf9VRPxOkiLiRER8HhHnJf1S0uLBtQmgqplcjbekLZLeiYifT1k/f8rTvi/pQP3tAajL\nTK7GL5H0Q0lv2t5frPuppNW2F0kKSYcl/WggHQKoxUyuxv9R0nS/j91ZfzsABoVv0AFJEHYgCcIO\nJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5IY6pTNtjuSjkxZNVfSqaE1\n8NWMam+j2pdEb/2qs7erI2Lav/821LBfcHC7HRGtxhooMaq9jWpfEr31a1i98TYeSIKwA0k0HfbN\nDR+/zKj2Nqp9SfTWr6H01uhndgDD0/SZHcCQEHYgiUbCbvt22+/aPmh7fRM9dGP7sO03i2mo2w33\nstX2SdsHpqy70vYu2+8V99POsddQbyMxjXfJNOONvnZNT38+9M/sti+R9D+Slko6Kuk1Sasj4u2h\nNtKF7cOSWhHR+BcwbN8k6aykZyPiumLdk5I+jIgNxX+UcyLin0ekt0clnW16Gu9itqL5U6cZl3SH\npH9Sg69dSV93aQivWxNn9sWSDkbEoYg4J+nXklY20MfIi4hXJH34pdUrJU0UyxOa/McydF16GwkR\ncTwi9hXLZyR9Mc14o69dSV9D0UTYr5L0pymPj2q05nsPSb+3vdf22qabmca8iDheLL8vaV6TzUyj\n5zTew/SlacZH5rXrZ/rzqrhAd6EbI+K7kpZLur94uzqSYvIz2CiNnc5oGu9hmWaa8T9r8rXrd/rz\nqpoI+zFJC6Y8/maxbiRExLHi/qSk7Rq9qahPfDGDbnF/suF+/myUpvGebppxjcBr1+T0502E/TVJ\n19j+lu1Zkn4gaUcDfVzA9uXFhRPZvlzSMo3eVNQ7JK0pltdIerHBXv7CqEzj3W2acTX82jU+/XlE\nDP0maYUmr8j/r6R/aaKHLn39vaTXi9tbTfcm6TlNvq37P01e27hX0t9J2i3pPUkvSbpyhHr7D0lv\nSnpDk8Ga31BvN2ryLfobkvYXtxVNv3YlfQ3ldePrskASXKADkiDsQBKEHUiCsANJEHYgCcIOJEHY\ngST+H8Q75A8bIkYhAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VM4GvfWO1DM",
        "colab_type": "text"
      },
      "source": [
        "# NN for MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5N7YWUZTLTO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0e9b289e-09bd-4519-d668-4e4ddf294579"
      },
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZVOzYZQTQhL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUANNg4cTVBV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eVPSbWtTWyW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(60000, 784).astype('float32') / 255.0\n",
        "X_test = X_test.reshape(10000, 784).astype('float32') / 255.0\n",
        "Y_train = np_utils.to_categorical(Y_train) # 원-핫 인코딩으로 바꿔줌\n",
        "Y_test = np_utils.to_categorical(Y_test)   # 원-핫 인코딩으로 바꿔줌"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7TQBQ1NThMD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "a2d22043-331b-4d8c-c87e-64703d14bf5f"
      },
      "source": [
        "print('X_train.shape:',X_train.shape)\n",
        "print('Y_train.shape:',Y_train.shape)"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train.shape: (60000, 784)\n",
            "Y_train.shape: (60000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KX_9-V6ITjfO",
        "colab_type": "text"
      },
      "source": [
        "## 신경망 구현\n",
        "- xavier 적용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VQ_X5_2V5dT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()  # xavier 가중치 초기화"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tl5S4JuFTqa7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X= tf.placeholder(tf.float32,[None,784])\n",
        "Y= tf.placeholder(tf.float32,[None,10])\n",
        "\n",
        "\n",
        "W1 = tf.get_variable(\"w1\", shape=[784, 392],\n",
        "           initializer=tf.contrib.layers.xavier_initializer())\n",
        "b1 = tf.Variable(tf.random_normal([392]),name='bias1')\n",
        "layers1 = tf.nn.relu(tf.matmul(X,W1)+b1)\n",
        "\n",
        "W2 = tf.get_variable(\"w2\", shape=[392, 196],\n",
        "           initializer=tf.contrib.layers.xavier_initializer())\n",
        "b2 = tf.Variable(tf.random_normal([196]),name='bias2')\n",
        "layers2 = tf.nn.relu(tf.matmul(layers1,W2)+b2)\n",
        "\n",
        "W3 = tf.get_variable(\"w3\", shape=[196, 10],\n",
        "           initializer=tf.contrib.layers.xavier_initializer())\n",
        "b3 = tf.Variable(tf.random_normal([10]),name='bias3')\n",
        "hypothesis = tf.nn.softmax(tf.matmul(layers2,W3)+b3)\n",
        "\n",
        "# cost/loss\n",
        "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(hypothesis),axis=1))\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
        "\n",
        "# Test model\n",
        "is_correct = tf.equal(tf.arg_max(hypothesis,1),tf.arg_max(Y,1)) #True, False로 나타냄.\n",
        "accuracy = tf.reduce_mean(tf.cast(is_correct,tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jC9UQSSRT0qD",
        "colab_type": "text"
      },
      "source": [
        "## Training epoch/batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anW1NFmoT2-A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "5f721fd5-edf6-43f4-c350-9023eadaf07d"
      },
      "source": [
        "training_epochs = 15\n",
        "batch_size =100\n",
        "total_batch = int(X_train.shape[0]/batch_size)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "\n",
        "  #Training Cycle\n",
        "  for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "\n",
        "    for i in range(total_batch):\n",
        "      #X_train 6만개의 사진중에 랜덤으로 100개를 가져와야함. <밑바닥 딥러닝 참고>\n",
        "      batch_mask = np.random.choice(X_train.shape[0], batch_size)\n",
        "      batch_xs,batch_ys = X_train[batch_mask],Y_train[batch_mask]\n",
        "\n",
        "      c,_  =sess.run([cost,optimizer],\n",
        "                     feed_dict={X:batch_xs,Y:batch_ys})\n",
        "      avg_cost += c/total_batch\n",
        "\n",
        "    print('Epoch:','%04d'%(epoch+1),\n",
        "              'cost = ','{:9f}'.format(avg_cost))\n",
        "  #Test the model using test sets\n",
        "  print('Accuracy:',accuracy.eval(session=sess,\n",
        "                                  feed_dict={X:X_test,Y:Y_test}))"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0001 cost =   0.446739\n",
            "Epoch: 0002 cost =   0.199483\n",
            "Epoch: 0003 cost =   0.138868\n",
            "Epoch: 0004 cost =   0.109602\n",
            "Epoch: 0005 cost =   0.087426\n",
            "Epoch: 0006 cost =   0.072619\n",
            "Epoch: 0007 cost =   0.060018\n",
            "Epoch: 0008 cost =   0.051477\n",
            "Epoch: 0009 cost =   0.043088\n",
            "Epoch: 0010 cost =   0.040428\n",
            "Epoch: 0011 cost =   0.034741\n",
            "Epoch: 0012 cost =   0.029691\n",
            "Epoch: 0013 cost =   0.029145\n",
            "Epoch: 0014 cost =   0.023368\n",
            "Epoch: 0015 cost =   0.020669\n",
            "Accuracy: 0.9796\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXJqFCgVWMQa",
        "colab_type": "text"
      },
      "source": [
        "# Dropout for MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NkbWU_MWQrf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph() # xavier 가중치 초기화"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJQgXKDuWTGp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X= tf.placeholder(tf.float32,[None,784])\n",
        "Y= tf.placeholder(tf.float32,[None,10])\n",
        "keep_prob = tf.placeholder(tf.float32)\n",
        "\n",
        "W1 = tf.get_variable(\"w1\", shape=[784, 392],\n",
        "           initializer=tf.contrib.layers.xavier_initializer())\n",
        "b1 = tf.Variable(tf.random_normal([392]),name='bias1')\n",
        "layers1 = tf.nn.relu(tf.matmul(X,W1)+b1)\n",
        "layers1 = tf.nn.dropout(layers1,keep_prob=keep_prob)\n",
        "\n",
        "W2 = tf.get_variable(\"w2\", shape=[392, 196],\n",
        "           initializer=tf.contrib.layers.xavier_initializer())\n",
        "b2 = tf.Variable(tf.random_normal([196]),name='bias2')\n",
        "layers2 = tf.nn.relu(tf.matmul(layers1,W2)+b2)\n",
        "layers2 = tf.nn.dropout(layers2,keep_prob=keep_prob)\n",
        "\n",
        "W3 = tf.get_variable(\"w3\", shape=[196, 10],\n",
        "           initializer=tf.contrib.layers.xavier_initializer())\n",
        "b3 = tf.Variable(tf.random_normal([10]),name='bias3')\n",
        "hypothesis = tf.nn.softmax(tf.matmul(layers2,W3)+b3)\n",
        "\n",
        "# cost/loss\n",
        "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(hypothesis),axis=1))\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
        "\n",
        "# Test model\n",
        "is_correct = tf.equal(tf.arg_max(hypothesis,1),tf.arg_max(Y,1)) #True, False로 나타냄.\n",
        "accuracy = tf.reduce_mean(tf.cast(is_correct,tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNrxj9a-XJ14",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "239c397a-3ecf-4a2c-a310-c3ca0a8502be"
      },
      "source": [
        "training_epochs = 15\n",
        "batch_size =100\n",
        "total_batch = int(X_train.shape[0]/batch_size)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "\n",
        "  #Training Cycle\n",
        "  for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "\n",
        "    for i in range(total_batch):\n",
        "      #X_train 6만개의 사진중에 랜덤으로 100개를 가져와야함. <밑바닥 딥러닝 참고>\n",
        "      batch_mask = np.random.choice(X_train.shape[0], batch_size)\n",
        "      batch_xs,batch_ys = X_train[batch_mask],Y_train[batch_mask]\n",
        "\n",
        "      c,_  =sess.run([cost,optimizer],\n",
        "                     feed_dict={X:batch_xs,Y:batch_ys,keep_prob:0.7})\n",
        "      avg_cost += c/total_batch\n",
        "\n",
        "    print('Epoch:','%04d'%(epoch+1),\n",
        "              'cost = ','{:9f}'.format(avg_cost))\n",
        "  #Test the model using test sets\n",
        "  print('Accuracy:',accuracy.eval(session=sess,\n",
        "                                  feed_dict={X:X_test,Y:Y_test,keep_prob:1}))"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0001 cost =   0.569160\n",
            "Epoch: 0002 cost =   0.272312\n",
            "Epoch: 0003 cost =   0.207728\n",
            "Epoch: 0004 cost =   0.174506\n",
            "Epoch: 0005 cost =   0.152259\n",
            "Epoch: 0006 cost =   0.134241\n",
            "Epoch: 0007 cost =   0.123430\n",
            "Epoch: 0008 cost =   0.110345\n",
            "Epoch: 0009 cost =   0.103189\n",
            "Epoch: 0010 cost =   0.093933\n",
            "Epoch: 0011 cost =   0.090315\n",
            "Epoch: 0012 cost =   0.080427\n",
            "Epoch: 0013 cost =   0.079173\n",
            "Epoch: 0014 cost =   0.075525\n",
            "Epoch: 0015 cost =   0.074058\n",
            "Accuracy: 0.9791\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}