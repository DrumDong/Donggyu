{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab_11_3: CNN class, layers, Ensemble.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DrumDong/Donggyu/blob/master/%EB%AA%A8%EB%91%90%EB%A5%BC%20%EC%9C%84%ED%95%9C%20%EB%94%A5%EB%9F%AC%EB%8B%9D/lab_11_3_CNN_class%2C_layers%2C_Ensemble.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrrqXXdl1cyM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrSnq8NJ2FJC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOA8YKGk0I9f",
        "colab_type": "text"
      },
      "source": [
        "# Python Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GymkeUlf0iRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model:\n",
        "\n",
        "    def __init__(self, sess, name):\n",
        "        self.sess = sess\n",
        "        self.name = name\n",
        "        self._build_net()\n",
        "\n",
        "    def _build_net(self):\n",
        "        with tf.variable_scope(self.name):\n",
        "            # dropout (keep_prob) rate  0.7~0.5 on training, but should be 1\n",
        "            # for testing\n",
        "            self.keep_prob = tf.placeholder(tf.float32)\n",
        "\n",
        "            # input place holders\n",
        "            self.X = tf.placeholder(tf.float32, [None, 784])\n",
        "            # img 28x28x1 (black/white)\n",
        "            X_img = tf.reshape(self.X, [-1, 28, 28, 1])\n",
        "            self.Y = tf.placeholder(tf.float32, [None, 10])\n",
        "\n",
        "            # L1 ImgIn shape=(?, 28, 28, 1)\n",
        "            W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
        "            #    Conv     -> (?, 28, 28, 32)\n",
        "            #    Pool     -> (?, 14, 14, 32)\n",
        "            L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
        "            L1 = tf.nn.relu(L1)\n",
        "            L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1],\n",
        "                                strides=[1, 2, 2, 1], padding='SAME')\n",
        "            L1 = tf.nn.dropout(L1, keep_prob=self.keep_prob)\n",
        "            '''\n",
        "            Tensor(\"Conv2D:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
        "            Tensor(\"Relu:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
        "            Tensor(\"MaxPool:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
        "            Tensor(\"dropout/mul:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
        "            '''\n",
        "\n",
        "            # L2 ImgIn shape=(?, 14, 14, 32)\n",
        "            W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
        "            #    Conv      ->(?, 14, 14, 64)\n",
        "            #    Pool      ->(?, 7, 7, 64)\n",
        "            L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
        "            L2 = tf.nn.relu(L2)\n",
        "            L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1],\n",
        "                                strides=[1, 2, 2, 1], padding='SAME')\n",
        "            L2 = tf.nn.dropout(L2, keep_prob=self.keep_prob)\n",
        "            '''\n",
        "            Tensor(\"Conv2D_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
        "            Tensor(\"Relu_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
        "            Tensor(\"MaxPool_1:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
        "            Tensor(\"dropout_1/mul:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
        "            '''\n",
        "\n",
        "            # L3 ImgIn shape=(?, 7, 7, 64)\n",
        "            W3 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev=0.01))\n",
        "            #    Conv      ->(?, 7, 7, 128)\n",
        "            #    Pool      ->(?, 4, 4, 128)\n",
        "            #    Reshape   ->(?, 4 * 4 * 128) # Flatten them for FC\n",
        "            L3 = tf.nn.conv2d(L2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
        "            L3 = tf.nn.relu(L3)\n",
        "            L3 = tf.nn.max_pool(L3, ksize=[1, 2, 2, 1], strides=[\n",
        "                                1, 2, 2, 1], padding='SAME')\n",
        "            L3 = tf.nn.dropout(L3, keep_prob=self.keep_prob)\n",
        "\n",
        "            L3_flat = tf.reshape(L3, [-1, 128 * 4 * 4])\n",
        "            '''\n",
        "            Tensor(\"Conv2D_2:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
        "            Tensor(\"Relu_2:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
        "            Tensor(\"MaxPool_2:0\", shape=(?, 4, 4, 128), dtype=float32)\n",
        "            Tensor(\"dropout_2/mul:0\", shape=(?, 4, 4, 128), dtype=float32)\n",
        "            Tensor(\"Reshape_1:0\", shape=(?, 2048), dtype=float32)\n",
        "            '''\n",
        "\n",
        "            # L4 FC 4x4x128 inputs -> 625 outputs\n",
        "            W4 = tf.get_variable(\"W4\", shape=[128 * 4 * 4, 625],\n",
        "                                 initializer=tf.contrib.layers.xavier_initializer())\n",
        "            b4 = tf.Variable(tf.random_normal([625]))\n",
        "            L4 = tf.nn.relu(tf.matmul(L3_flat, W4) + b4)\n",
        "            L4 = tf.nn.dropout(L4, keep_prob=self.keep_prob)\n",
        "            '''\n",
        "            Tensor(\"Relu_3:0\", shape=(?, 625), dtype=float32)\n",
        "            Tensor(\"dropout_3/mul:0\", shape=(?, 625), dtype=float32)\n",
        "            '''\n",
        "\n",
        "            # L5 Final FC 625 inputs -> 10 outputs\n",
        "            W5 = tf.get_variable(\"W5\", shape=[625, 10],\n",
        "                                 initializer=tf.contrib.layers.xavier_initializer())\n",
        "            b5 = tf.Variable(tf.random_normal([10]))\n",
        "            self.logits = tf.matmul(L4, W5) + b5\n",
        "            '''\n",
        "            Tensor(\"add_1:0\", shape=(?, 10), dtype=float32)\n",
        "            '''\n",
        "\n",
        "        # define cost/loss & optimizer\n",
        "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
        "            logits=self.logits, labels=self.Y))\n",
        "        self.optimizer = tf.train.AdamOptimizer(\n",
        "            learning_rate=learning_rate).minimize(self.cost)\n",
        "\n",
        "        correct_prediction = tf.equal(\n",
        "            tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))\n",
        "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "    def predict(self, x_test, keep_prop=1.0):\n",
        "        return self.sess.run(self.logits, feed_dict={self.X: x_test, self.keep_prob: keep_prop})\n",
        "\n",
        "    def get_accuracy(self, x_test, y_test, keep_prop=1.0):\n",
        "        return self.sess.run(self.accuracy, feed_dict={self.X: x_test, self.Y: y_test, self.keep_prob: keep_prop})\n",
        "\n",
        "    def train(self, x_data, y_data, keep_prop=0.7):\n",
        "        return self.sess.run([self.cost, self.optimizer], feed_dict={\n",
        "            self.X: x_data, self.Y: y_data, self.keep_prob: keep_prop})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15VXmv9q1oe7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "cdb4cf48-e6b4-4b64-92b0-7b74aa5ae5b5"
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
        "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
        "# more information about the mnist dataset\n",
        "\n",
        "# hyper parameters\n",
        "learning_rate = 0.001\n",
        "training_epochs = 15\n",
        "batch_size = 100"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bV8efA3x1VdZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "d1d7e7a7-1afa-4287-af1d-d7d1716c7753"
      },
      "source": [
        "# initialize\n",
        "sess = tf.Session()\n",
        "m1 = Model(sess, \"m1\")\n",
        "\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "print('Learning Started!')\n",
        "\n",
        "# train my model\n",
        "for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "    total_batch = int(mnist.train.num_examples / batch_size)\n",
        "\n",
        "    for i in range(total_batch):\n",
        "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "        c, _ = m1.train(batch_xs, batch_ys)\n",
        "        avg_cost += c / total_batch\n",
        "\n",
        "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
        "\n",
        "print('Learning Finished!')\n",
        "\n",
        "# Test model and check accuracy\n",
        "print('Accuracy:', m1.get_accuracy(mnist.test.images, mnist.test.labels))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning Started!\n",
            "Epoch: 0001 cost = 0.381739971\n",
            "Epoch: 0002 cost = 0.096260108\n",
            "Epoch: 0003 cost = 0.072427663\n",
            "Epoch: 0004 cost = 0.061014256\n",
            "Epoch: 0005 cost = 0.053525738\n",
            "Epoch: 0006 cost = 0.047802749\n",
            "Epoch: 0007 cost = 0.043050691\n",
            "Epoch: 0008 cost = 0.038893874\n",
            "Epoch: 0009 cost = 0.035564992\n",
            "Epoch: 0010 cost = 0.034243706\n",
            "Epoch: 0011 cost = 0.032277348\n",
            "Epoch: 0012 cost = 0.031493142\n",
            "Epoch: 0013 cost = 0.029597204\n",
            "Epoch: 0014 cost = 0.026872390\n",
            "Epoch: 0015 cost = 0.027775628\n",
            "Learning Finished!\n",
            "Accuracy: 0.9945\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FnQxp2G2Nqv",
        "colab_type": "text"
      },
      "source": [
        "# tf.layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W99-Kta-2PhT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model_uselayers:\n",
        "\n",
        "    def __init__(self, sess, name):\n",
        "        self.sess = sess\n",
        "        self.name = name\n",
        "        self._build_net()\n",
        "\n",
        "    def _build_net(self):\n",
        "        with tf.variable_scope(self.name):\n",
        "            # dropout (keep_prob) rate  0.7~0.5 on training, but should be 1\n",
        "            # for testing\n",
        "            self.training = tf.placeholder(tf.bool)\n",
        "\n",
        "            # input place holders\n",
        "            self.X = tf.placeholder(tf.float32, [None, 784])\n",
        "\n",
        "            # img 28x28x1 (black/white), Input Layer\n",
        "            X_img = tf.reshape(self.X, [-1, 28, 28, 1])\n",
        "            self.Y = tf.placeholder(tf.float32, [None, 10])\n",
        "\n",
        "            # Convolutional Layer #1\n",
        "            conv1 = tf.layers.conv2d(inputs=X_img, filters=32, kernel_size=[3, 3],\n",
        "                                     padding=\"SAME\", activation=tf.nn.relu)\n",
        "            # Pooling Layer #1\n",
        "            pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2],\n",
        "                                            padding=\"SAME\", strides=2)\n",
        "            dropout1 = tf.layers.dropout(inputs=pool1,\n",
        "                                         rate=0.3, training=self.training)\n",
        "\n",
        "            # Convolutional Layer #2 and Pooling Layer #2\n",
        "            conv2 = tf.layers.conv2d(inputs=dropout1, filters=64, kernel_size=[3, 3],\n",
        "                                     padding=\"SAME\", activation=tf.nn.relu)\n",
        "            pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2],\n",
        "                                            padding=\"SAME\", strides=2)\n",
        "            dropout2 = tf.layers.dropout(inputs=pool2,\n",
        "                                         rate=0.3, training=self.training)\n",
        "\n",
        "            # Convolutional Layer #2 and Pooling Layer #2\n",
        "            conv3 = tf.layers.conv2d(inputs=dropout2, filters=128, kernel_size=[3, 3],\n",
        "                                     padding=\"same\", activation=tf.nn.relu)\n",
        "            pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2],\n",
        "                                            padding=\"same\", strides=2)\n",
        "            dropout3 = tf.layers.dropout(inputs=pool3,\n",
        "                                         rate=0.3, training=self.training)\n",
        "\n",
        "            # Dense Layer with Relu\n",
        "            flat = tf.reshape(dropout3, [-1, 128 * 4 * 4])\n",
        "            dense4 = tf.layers.dense(inputs=flat,\n",
        "                                     units=625, activation=tf.nn.relu)\n",
        "            dropout4 = tf.layers.dropout(inputs=dense4,\n",
        "                                         rate=0.5, training=self.training)\n",
        "\n",
        "            # Logits (no activation) Layer: L5 Final FC 625 inputs -> 10 outputs\n",
        "            self.logits = tf.layers.dense(inputs=dropout4, units=10)\n",
        "\n",
        "        # define cost/loss & optimizer\n",
        "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
        "            logits=self.logits, labels=self.Y))\n",
        "        self.optimizer = tf.train.AdamOptimizer(\n",
        "            learning_rate=learning_rate).minimize(self.cost)\n",
        "\n",
        "        correct_prediction = tf.equal(\n",
        "            tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))\n",
        "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "    def predict(self, x_test, training=False):\n",
        "        return self.sess.run(self.logits,\n",
        "                             feed_dict={self.X: x_test, self.training: training})\n",
        "\n",
        "    def get_accuracy(self, x_test, y_test, training=False):\n",
        "        return self.sess.run(self.accuracy,\n",
        "                             feed_dict={self.X: x_test,\n",
        "                                        self.Y: y_test, self.training: training})\n",
        "\n",
        "    def train(self, x_data, y_data, training=True):\n",
        "        return self.sess.run([self.cost, self.optimizer], feed_dict={\n",
        "            self.X: x_data, self.Y: y_data, self.training: training})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76gjMixt7pXp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "outputId": "64a5f40b-ee67-4010-bca2-4625138f70db"
      },
      "source": [
        "# initialize\n",
        "sess = tf.Session()\n",
        "m1 = Model_uselayers(sess, \"m1\")\n",
        "\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "print('Learning Started!')\n",
        "\n",
        "# train my model\n",
        "for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "    total_batch = int(mnist.train.num_examples / batch_size)\n",
        "\n",
        "    for i in range(total_batch):\n",
        "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "        c, _ = m1.train(batch_xs, batch_ys)\n",
        "        avg_cost += c / total_batch\n",
        "\n",
        "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
        "\n",
        "print('Learning Finished!')\n",
        "\n",
        "# Test model and check accuracy\n",
        "print('Accuracy:', m1.get_accuracy(mnist.test.images, mnist.test.labels))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-17-a6954910cad1>:23: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2D` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From <ipython-input-17-a6954910cad1>:26: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.MaxPooling2D instead.\n",
            "WARNING:tensorflow:From <ipython-input-17-a6954910cad1>:28: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dropout instead.\n",
            "WARNING:tensorflow:From <ipython-input-17-a6954910cad1>:49: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "Learning Started!\n",
            "Epoch: 0001 cost = 0.283802913\n",
            "Epoch: 0002 cost = 0.093108358\n",
            "Epoch: 0003 cost = 0.068430393\n",
            "Epoch: 0004 cost = 0.056827713\n",
            "Epoch: 0005 cost = 0.049472117\n",
            "Epoch: 0006 cost = 0.046686823\n",
            "Epoch: 0007 cost = 0.041993822\n",
            "Epoch: 0008 cost = 0.040900829\n",
            "Epoch: 0009 cost = 0.038317367\n",
            "Epoch: 0010 cost = 0.033285898\n",
            "Epoch: 0011 cost = 0.032930024\n",
            "Epoch: 0012 cost = 0.028680027\n",
            "Epoch: 0013 cost = 0.030746296\n",
            "Epoch: 0014 cost = 0.026968278\n",
            "Epoch: 0015 cost = 0.025977914\n",
            "Learning Finished!\n",
            "Accuracy: 0.9932\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMbFgOXn8qsk",
        "colab_type": "text"
      },
      "source": [
        "# Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km2YqVEQ8zUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model_Ensemble:\n",
        "\n",
        "    def __init__(self, sess, name):\n",
        "        self.sess = sess\n",
        "        self.name = name\n",
        "        self._build_net()\n",
        "\n",
        "    def _build_net(self):\n",
        "        with tf.variable_scope(self.name):\n",
        "            # dropout (keep_prob) rate  0.7~0.5 on training, but should be 1\n",
        "            # for testing\n",
        "            self.training = tf.placeholder(tf.bool)\n",
        "\n",
        "            # input place holders\n",
        "            self.X = tf.placeholder(tf.float32, [None, 784])\n",
        "\n",
        "            # img 28x28x1 (black/white), Input Layer\n",
        "            X_img = tf.reshape(self.X, [-1, 28, 28, 1])\n",
        "            self.Y = tf.placeholder(tf.float32, [None, 10])\n",
        "\n",
        "            # Convolutional Layer #1\n",
        "            conv1 = tf.layers.conv2d(inputs=X_img, filters=32, kernel_size=[3, 3],\n",
        "                                     padding=\"SAME\", activation=tf.nn.relu)\n",
        "            # Pooling Layer #1\n",
        "            pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2],\n",
        "                                            padding=\"SAME\", strides=2)\n",
        "            dropout1 = tf.layers.dropout(inputs=pool1,\n",
        "                                         rate=0.3, training=self.training)\n",
        "\n",
        "            # Convolutional Layer #2 and Pooling Layer #2\n",
        "            conv2 = tf.layers.conv2d(inputs=dropout1, filters=64, kernel_size=[3, 3],\n",
        "                                     padding=\"SAME\", activation=tf.nn.relu)\n",
        "            pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2],\n",
        "                                            padding=\"SAME\", strides=2)\n",
        "            dropout2 = tf.layers.dropout(inputs=pool2,\n",
        "                                         rate=0.3, training=self.training)\n",
        "\n",
        "            # Convolutional Layer #3 and Pooling Layer #3\n",
        "            conv3 = tf.layers.conv2d(inputs=dropout2, filters=128, kernel_size=[3, 3],\n",
        "                                     padding=\"SAME\", activation=tf.nn.relu)\n",
        "            pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2],\n",
        "                                            padding=\"SAME\", strides=2)\n",
        "            dropout3 = tf.layers.dropout(inputs=pool3,\n",
        "                                         rate=0.3, training=self.training)\n",
        "\n",
        "            # Dense Layer with Relu\n",
        "            flat = tf.reshape(dropout3, [-1, 128 * 4 * 4])\n",
        "            dense4 = tf.layers.dense(inputs=flat,\n",
        "                                     units=625, activation=tf.nn.relu)\n",
        "            dropout4 = tf.layers.dropout(inputs=dense4,\n",
        "                                         rate=0.5, training=self.training)\n",
        "\n",
        "            # Logits (no activation) Layer: L5 Final FC 625 inputs -> 10 outputs\n",
        "            self.logits = tf.layers.dense(inputs=dropout4, units=10)\n",
        "\n",
        "        # define cost/loss & optimizer\n",
        "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
        "            logits=self.logits, labels=self.Y))\n",
        "        self.optimizer = tf.train.AdamOptimizer(\n",
        "            learning_rate=learning_rate).minimize(self.cost)\n",
        "\n",
        "        correct_prediction = tf.equal(\n",
        "            tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))\n",
        "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "    def predict(self, x_test, training=False):\n",
        "        return self.sess.run(self.logits,\n",
        "                             feed_dict={self.X: x_test, self.training: training})\n",
        "\n",
        "    def get_accuracy(self, x_test, y_test, training=False):\n",
        "        return self.sess.run(self.accuracy,\n",
        "                             feed_dict={self.X: x_test,\n",
        "                                        self.Y: y_test, self.training: training})\n",
        "\n",
        "    def train(self, x_data, y_data, training=True):\n",
        "        return self.sess.run([self.cost, self.optimizer], feed_dict={\n",
        "            self.X: x_data, self.Y: y_data, self.training: training})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5TUn_18850j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "a3697abc-e7ea-4498-c31f-ea961f50eef6"
      },
      "source": [
        "# initialize\n",
        "sess = tf.Session()\n",
        "\n",
        "models = []\n",
        "num_models = 2\n",
        "for m in range(num_models):\n",
        "    models.append(Model_Ensemble(sess, \"model\" + str(m)))\n",
        "\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "print('Learning Started!')\n",
        "\n",
        "# train my model\n",
        "for epoch in range(training_epochs):\n",
        "    avg_cost_list = np.zeros(len(models))\n",
        "    total_batch = int(mnist.train.num_examples / batch_size)\n",
        "    for i in range(total_batch):\n",
        "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "\n",
        "        # train each model\n",
        "        for m_idx, m in enumerate(models):\n",
        "            c, _ = m.train(batch_xs, batch_ys)\n",
        "            avg_cost_list[m_idx] += c / total_batch\n",
        "\n",
        "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', avg_cost_list)\n",
        "\n",
        "print('Learning Finished!')\n",
        "\n",
        "# Test model and check accuracy\n",
        "test_size = len(mnist.test.labels)\n",
        "predictions = np.zeros([test_size, 10])\n",
        "for m_idx, m in enumerate(models):\n",
        "    print(m_idx, 'Accuracy:', m.get_accuracy(\n",
        "        mnist.test.images, mnist.test.labels))\n",
        "    p = m.predict(mnist.test.images)\n",
        "    predictions += p\n",
        "\n",
        "ensemble_correct_prediction = tf.equal(\n",
        "    tf.argmax(predictions, 1), tf.argmax(mnist.test.labels, 1))\n",
        "ensemble_accuracy = tf.reduce_mean(\n",
        "    tf.cast(ensemble_correct_prediction, tf.float32))\n",
        "print('Ensemble accuracy:', sess.run(ensemble_accuracy))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning Started!\n",
            "Epoch: 0001 cost = [0.28775775 0.28705697]\n",
            "Epoch: 0002 cost = [0.08662426 0.08679999]\n",
            "Epoch: 0003 cost = [0.06755769 0.06350916]\n",
            "Epoch: 0004 cost = [0.05525524 0.05552303]\n",
            "Epoch: 0005 cost = [0.04975844 0.04912756]\n",
            "Epoch: 0006 cost = [0.04371996 0.04405557]\n",
            "Epoch: 0007 cost = [0.04021457 0.03731273]\n",
            "Epoch: 0008 cost = [0.03929648 0.03647372]\n",
            "Epoch: 0009 cost = [0.03528198 0.03467335]\n",
            "Epoch: 0010 cost = [0.03421965 0.03313995]\n",
            "Epoch: 0011 cost = [0.03100158 0.03220859]\n",
            "Epoch: 0012 cost = [0.02981186 0.03047469]\n",
            "Epoch: 0013 cost = [0.02839555 0.02757842]\n",
            "Epoch: 0014 cost = [0.02629753 0.02712845]\n",
            "Epoch: 0015 cost = [0.02565704 0.02619997]\n",
            "Learning Finished!\n",
            "0 Accuracy: 0.9931\n",
            "1 Accuracy: 0.9938\n",
            "Ensemble accuracy: 0.9951\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}